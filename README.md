# MediaPipe Avatar VRM - Fullscreen Edition

Una aplicaciÃ³n web avanzada que combina **MediaPipe**, **Kalidokit** y **Three.js** para crear un avatar VRM animado en tiempo real que imita expresiones faciales y gestos de manos con experiencia fullscreen optimizada.

## ğŸš€ CaracterÃ­sticas

- **DetecciÃ³n facial en tiempo real** usando MediaPipe Face Landmarker
- **Seguimiento de expresiones faciales** con 52 blendshapes
- **Avatares VRM animados** con soporte para expresiones y rotaciones
- **ConversiÃ³n inteligente** de landmarks MediaPipe a rotaciones VRM usando Kalidokit
- **Suavizado de movimientos** para animaciones naturales
- **Interfaz moderna** con controles en tiempo real
- **Soporte para avatares personalizados** (.vrm)
- **MÃ©tricas de rendimiento** (FPS, latencia)
- **Panel de debugging** para desarrolladores

## ğŸ›  TecnologÃ­as Utilizadas

- **MediaPipe Tasks Vision**: DetecciÃ³n y anÃ¡lisis facial
- **Kalidokit**: ConversiÃ³n de landmarks a datos de rigging
- **Three.js**: Renderizado 3D
- **@pixiv/three-vrm**: Soporte para modelos VRM
- **Vite**: Bundler y servidor de desarrollo
- **Vanilla JavaScript**: Sin frameworks, mÃ¡ximo rendimiento

## ğŸ“ Estructura del Proyecto

```
src/
â”œâ”€â”€ tracking/
â”‚   â””â”€â”€ faceTracker.js          # Gestor de MediaPipe Face Landmarker
â”œâ”€â”€ avatar/
â”‚   â””â”€â”€ vrmAvatarManager.js     # Gestor de avatares VRM y Three.js
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ kalidokitAdapter.js     # Adaptador para Kalidokit
â”‚   â”œâ”€â”€ avatarRigService.js     # Servicio principal de coordinaciÃ³n
â”‚   â””â”€â”€ blendshapeMapping.json  # Mapeo MediaPipe â†’ VRM
â”œâ”€â”€ assets/                     # Recursos estÃ¡ticos
â”œâ”€â”€ main.js                     # AplicaciÃ³n principal
â””â”€â”€ style.css                  # Estilos de la interfaz
```

## ğŸš¦ InstalaciÃ³n y Uso

### Prerequisitos

- Node.js (v16 o superior)
- Navegador moderno con soporte para WebRTC y WebGL
- CÃ¡mara web funcional

### InstalaciÃ³n

1. **Clonar el repositorio**:
   ```bash
   git clone <url-del-repositorio>
   cd JuegoMediaPipe
   ```

2. **Instalar dependencias**:
   ```bash
   npm install
   ```

3. **Iniciar el servidor de desarrollo**:
   ```bash
   npm run dev
   ```

4. **Abrir en el navegador**:
   - Ir a `http://localhost:5173`
   - Permitir acceso a la cÃ¡mara cuando se solicite

### Build para ProducciÃ³n

```bash
npm run build
```

Los archivos de producciÃ³n se generarÃ¡n en la carpeta `dist/`.

## ğŸ® CÃ³mo Usar

1. **Inicializar**: La aplicaciÃ³n se carga automÃ¡ticamente con un avatar por defecto
2. **Seleccionar avatar**: Elige entre los avatares disponibles o carga tu propio archivo .vrm
3. **Iniciar tracking**: Haz clic en "Iniciar Tracking" para comenzar la detecciÃ³n facial
4. **Ajustar configuraciÃ³n**: Usa los controles para modificar suavizado, expresiones, etc.
5. **Recalibrar**: Usa el botÃ³n "Recalibrar" para resetear la pose neutral
6. **Debug**: Doble clic en el header para mostrar informaciÃ³n de debugging

## ğŸ› Controles de ConfiguraciÃ³n

- **Suavizado**: Controla la suavidad de las transiciones (0.0 = sin suavizado, 1.0 = mÃ¡ximo suavizado)
- **Expresiones faciales**: Habilita/deshabilita el mapeo de blendshapes
- **RotaciÃ³n de cabeza**: Controla si el avatar sigue los movimientos de cabeza
- **Recalibrar**: Establece la pose actual como neutral

## ğŸ”§ ConfiguraciÃ³n Avanzada

### Mapeo de Blendshapes

El archivo `src/utils/blendshapeMapping.json` contiene el mapeo entre los blendshapes de MediaPipe y las expresiones VRM. Puedes modificarlo para ajustar la correspondencia:

```json
{
  "mediaPipeToVRM": {
    "eyeBlinkLeft": "blink_l",
    "eyeBlinkRight": "blink_r",
    "mouthSmileLeft": "happy",
    // ... mÃ¡s mapeos
  }
}
```

### ConfiguraciÃ³n de Video

En `src/main.js`, puedes ajustar la configuraciÃ³n de video:

```javascript
const CONFIG = {
    video: {
        width: 640,
        height: 480,
        facingMode: "user"
    }
};
```

### ConfiguraciÃ³n de Rendimiento

Para optimizar el rendimiento, ajusta estos parÃ¡metros en el servicio:

```javascript
avatarRigService.setConfig({
    targetFPS: 30,
    enableSmoothing: true,
    smoothingFactor: 0.7
});
```

## ğŸ“Š MÃ©tricas de Rendimiento

La aplicaciÃ³n muestra en tiempo real:
- **FPS**: Frames por segundo de procesamiento
- **Latencia**: Tiempo de procesamiento por frame en milisegundos
- **Landmarks detectados**: Cantidad de puntos faciales identificados
- **Blendshapes activos**: Expresiones faciales siendo procesadas

## ğŸ¨ Personalizar Avatares

### Usar Avatares VRM Existentes

La aplicaciÃ³n incluye avatares de ejemplo, pero puedes usar cualquier modelo VRM:

1. **VRM Hub**: [https://hub.vroid.com](https://hub.vroid.com)
2. **VRoid Studio**: Crear avatares personalizados
3. **Booth**: Marketplace de avatares VRM

### Crear Avatares Compatibles

Para mÃ¡xima compatibilidad, asegÃºrate de que tu avatar VRM incluya:
- Blendshapes estÃ¡ndar (blink, happy, sad, etc.)
- Huesos humanoides correctamente rigged
- Expresiones faciales configuradas

### Mapeo de Expresiones

Si tu avatar usa nombres de expresiones diferentes, modifica el mapeo en `blendshapeMapping.json`:

```json
{
  "mediaPipeToVRM": {
    "mouthSmileLeft": "tu_nombre_de_expresion_feliz"
  }
}
```

## ğŸ”§ Desarrollo y API

### Servicios Principales

#### `AvatarRigService`

Servicio principal que coordina tracking facial y animaciÃ³n del avatar:

```javascript
import { getAvatarRigService } from './utils/avatarRigService.js';

const service = getAvatarRigService();
await service.initialize(containerElement);
await service.loadAvatar(vrmUrl);
service.startTracking(videoElement);
```

#### `FaceTracker`

Gestiona MediaPipe Face Landmarker:

```javascript
import { getFaceTracker } from './tracking/faceTracker.js';

const tracker = getFaceTracker();
await tracker.initialize();
const results = tracker.processFrame(videoElement);
```

#### `VRMAvatarManager`

Maneja la carga y animaciÃ³n de avatares VRM:

```javascript
import { VRMAvatarManager } from './avatar/vrmAvatarManager.js';

const manager = new VRMAvatarManager(container);
await manager.loadVRM(url);
manager.updateAvatar(faceData);
```

### Callbacks y Eventos

```javascript
avatarRigService.onFaceDetected((results) => {
    // Procesar detecciÃ³n facial
});

avatarRigService.onAvatarUpdated((data) => {
    // Avatar actualizado
});

avatarRigService.onPerformanceUpdate((metrics) => {
    // MÃ©tricas de rendimiento
});
```

## ğŸ› SoluciÃ³n de Problemas

### Problemas Comunes

1. **Error de cÃ¡mara**: Verificar permisos del navegador
2. **Avatar no carga**: Verificar formato VRM y URL vÃ¡lida
3. **Bajo FPS**: Reducir resoluciÃ³n de video o deshabilitar suavizado
4. **Expresiones no responden**: Verificar mapeo de blendshapes

### Debug

Activa el panel de debug haciendo doble clic en el header para ver:
- Estado del tracking facial
- Valores de blendshapes en tiempo real
- InformaciÃ³n del avatar cargado
- MÃ©tricas de rendimiento detalladas

### OptimizaciÃ³n

Para mejorar el rendimiento:
- Usar resoluciÃ³n de video mÃ¡s baja (480p)
- Reducir factor de suavizado
- Deshabilitar expresiones no necesarias
- Usar avatares VRM optimizados

## ğŸ¤ Contribuir

1. Fork el proyecto
2. Crea una rama para tu feature (`git checkout -b feature/nueva-funcionalidad`)
3. Commit tus cambios (`git commit -m 'Agregar nueva funcionalidad'`)
4. Push a la rama (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia ISC. Ver el archivo `LICENSE` para mÃ¡s detalles.

## ğŸ™ Agradecimientos

- **MediaPipe Team** por las herramientas de computer vision
- **Kalidokit** por la conversiÃ³n de landmarks
- **VRM Consortium** por el estÃ¡ndar de avatares 3D
- **Three.js** por el motor de renderizado 3D

## ğŸ“ Soporte

Para reportar bugs o solicitar caracterÃ­sticas:
- Abrir un issue en GitHub
- Proporcionar informaciÃ³n detallada del problema
- Incluir informaciÃ³n del navegador y sistema operativo

---

**Â¡Disfruta creando avatares animados con expresiones faciales en tiempo real!** ğŸ­